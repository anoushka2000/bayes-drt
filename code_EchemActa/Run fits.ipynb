{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to apply `bayes-drt` to the example spectra presented in the manuscript. The code to apply the Gaussian Process and Elastic Net DRT models to the same data can be found in the `comparisons` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if '../bayes-drt' not in sys.path:\n",
    "    sys.path.append('../bayes-drt')\n",
    "import drt\n",
    "from stan_models import save_pickle,load_pickle\n",
    "import eis_utils as gt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n",
      "../bayes-drt\\drt.py:1049: RuntimeWarning: overflow encountered in exp\n",
      "  return phi(y,epsilon)/(1+np.exp(2*(y+np.log(w_n*t_m))))\n",
      "../bayes-drt\\drt.py:327: UserWarning: Hyperparametric solution did not converge within 20 iterations\n",
      "  warnings.warn(f'Hyperparametric solution did not converge within {max_iter} iterations')\n"
     ]
    }
   ],
   "source": [
    "dr = drt.DRT()\n",
    "files = glob.glob('../data/simulated/Z_*.csv')\n",
    "files = [f for f in files if f.find('trunc')==-1]\n",
    "# fit one file to generate A matrices\n",
    "df = pd.read_csv(files[0])\n",
    "Z = df['Zreal'] + 1j*df['Zimag']\n",
    "dr.ridge_fit(df['Freq'].values,Z.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Macdonald_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 12.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\stan_models.py:7: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped pickle to map_results\\obj_2RC_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Macdonald_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 6.97 seconds\n",
      "Dumped pickle to map_results\\obj_2RC_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Macdonald_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 3.50 seconds\n",
      "Dumped pickle to map_results\\obj_2RC_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_noiseless.csv\n",
      "-------------------------------\n",
      "Already ran\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Orazem_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 17.38 seconds\n",
      "Dumped pickle to map_results\\obj_2RC_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Orazem_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 4.86 seconds\n",
      "Dumped pickle to map_results\\obj_2RC_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Orazem_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.77 seconds\n",
      "Dumped pickle to map_results\\obj_2RC_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_uniform_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 13.53 seconds\n",
      "Dumped pickle to map_results\\obj_2RC_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_uniform_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 8.68 seconds\n",
      "Dumped pickle to map_results\\obj_2RC_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_uniform_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 3.26 seconds\n",
      "Dumped pickle to map_results\\obj_2RC_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Macdonald_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 7.73 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Macdonald_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.08 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Macdonald_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.07 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_noiseless.csv\n",
      "-------------------------------\n",
      "Already ran\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Orazem_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 3.49 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Orazem_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 1.76 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Orazem_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.51 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_uniform_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 3.73 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_uniform_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 1.21 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_uniform_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.29 seconds\n",
      "Dumped pickle to map_results\\obj_2ZARC_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Macdonald_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 5.78 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Macdonald_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.09 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Macdonald_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 2.02 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_noiseless.csv\n",
      "-------------------------------\n",
      "Already ran\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Orazem_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 4.99 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Orazem_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.49 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Orazem_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.97 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_uniform_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 6.13 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_uniform_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.44 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_uniform_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 2.10 seconds\n",
      "Dumped pickle to map_results\\obj_Gerischer_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Macdonald_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 7.88 seconds\n",
      "Dumped pickle to map_results\\obj_RC_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Macdonald_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 4.24 seconds\n",
      "Dumped pickle to map_results\\obj_RC_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Macdonald_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 2.09 seconds\n",
      "Dumped pickle to map_results\\obj_RC_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_noiseless.csv\n",
      "-------------------------------\n",
      "Already ran\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Orazem_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 11.06 seconds\n",
      "Dumped pickle to map_results\\obj_RC_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Orazem_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.65 seconds\n",
      "Dumped pickle to map_results\\obj_RC_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Orazem_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.56 seconds\n",
      "Dumped pickle to map_results\\obj_RC_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_uniform_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 6.67 seconds\n",
      "Dumped pickle to map_results\\obj_RC_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_uniform_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.15 seconds\n",
      "Dumped pickle to map_results\\obj_RC_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_uniform_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 2.41 seconds\n",
      "Dumped pickle to map_results\\obj_RC_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Macdonald_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 4.18 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC-RL_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Macdonald_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.48 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC-RL_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Macdonald_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.68 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC-RL_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_noiseless.csv\n",
      "-------------------------------\n",
      "Already ran\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Orazem_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 4.78 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC-RL_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Orazem_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 1.84 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped pickle to map_results\\obj_ZARC-RL_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Orazem_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.32 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC-RL_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_uniform_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 4.56 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC-RL_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_uniform_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.10 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC-RL_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_uniform_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 2.01 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC-RL_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Macdonald_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 5.87 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Macdonald_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 3.02 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Macdonald_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 2.89 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_noiseless.csv\n",
      "-------------------------------\n",
      "Already ran\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Orazem_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 7.73 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Orazem_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.37 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Orazem_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 2.04 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_uniform_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 6.54 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_uniform_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.25 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_uniform_2.5.csv\n",
      "-------------------------------\n",
      "File fit time: 1.66 seconds\n",
      "Dumped pickle to map_results\\obj_ZARC_uniform_2.5.pkl\n",
      "================================\n",
      "Total fit time: 4.31 minutes\n"
     ]
    }
   ],
   "source": [
    "\"MAP fits\"\n",
    "# tau for plotting\n",
    "tau_plot = np.logspace(-7,2,200)\n",
    "start = time.time()\n",
    "\n",
    "for file in files:\n",
    "    print('-------------------------------')\n",
    "    print(file)\n",
    "    print('-------------------------------')\n",
    "    suffix = file[file.find('_'):]\n",
    "    Zoutfile = os.path.join('map_results',f'Zout{suffix}')\n",
    "    Goutfile = os.path.join('map_results',f'Gout{suffix}')\n",
    "    pkl = os.path.join('map_results','obj{}.pkl'.format(suffix[:-4]))\n",
    "    if file.split('_')[2]=='noiseless.csv':\n",
    "        sigma_min=0.005\n",
    "    else:\n",
    "        sigma_min=0.002\n",
    "    if os.path.exists(Zoutfile) and os.path.exists(Goutfile):\n",
    "        print('Already ran')\n",
    "    else:\n",
    "        df = pd.read_csv(file)\n",
    "        Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "        # fit\n",
    "        file_start = time.time()\n",
    "        dr.map_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=False,sigma_min=sigma_min)\n",
    "        print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "        \n",
    "        # save results\n",
    "        Z_pred = dr.predict(df['Freq'].values)\n",
    "        Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag]).T,columns=['freq','Zreal','Zimag'])\n",
    "        Z_res['sigma_re'] = dr._opt_result['sigma_tot'][:len(df)]*dr._Z_scale\n",
    "        Z_res['sigma_im'] = dr._opt_result['sigma_tot'][len(df):]*dr._Z_scale\n",
    "        \n",
    "        g_pred = dr.drt(eval_tau=tau_plot)\n",
    "        g_res = pd.DataFrame(np.array([tau_plot,g_pred]).T,\n",
    "                             columns=['tau','gamma'])\n",
    "        Z_res.to_csv(Zoutfile,index=False)\n",
    "        g_res.to_csv(Goutfile,index=False)\n",
    "        \n",
    "        # pickle the drt object for access to all other attributes\n",
    "        save_pickle(dr,pkl)\n",
    "        \n",
    "print('================================')        \n",
    "print('Total fit time: {:.2f} minutes'.format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Macdonald_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\drt.py:311: UserWarning: Hyperparametric solution did not converge within 20 iterations\n",
      "  warnings.warn(f'Hyperparametric solution did not converge within {max_iter} iterations')\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 129.66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\stan_models.py:7: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped pickle to bayes_results\\obj_2RC_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Macdonald_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 71.71 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Macdonald_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 72.95 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_noiseless.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 129.19 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_noiseless.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Orazem_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:399 of 400 iterations saturated the maximum tree depth of 10 (99.8 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 128.51 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Orazem_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 69.31 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_Orazem_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 68.82 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_uniform_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 129.56 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_uniform_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 94.12 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2RC_uniform_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 64.35 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Macdonald_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 67.48 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Macdonald_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations ended with a divergence (0.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 65.59 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Macdonald_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 68.51 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_noiseless.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 81.96 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_noiseless.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Orazem_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 66.42 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Orazem_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 68.83 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_Orazem_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 65.04 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_uniform_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 71.09 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_uniform_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 68.85 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_2ZARC_uniform_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 64.74 seconds\n",
      "Dumped pickle to bayes_results\\obj_2ZARC_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Macdonald_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 86.78 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Macdonald_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 62.65 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Macdonald_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 66.83 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_noiseless.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:99 of 400 iterations saturated the maximum tree depth of 10 (24.8 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 108.52 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_noiseless.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Orazem_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 88.28 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Orazem_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 60.61 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_Orazem_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 69.56 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_uniform_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:3 of 400 iterations saturated the maximum tree depth of 10 (0.75 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 88.00 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_uniform_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 65.77 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_Gerischer_uniform_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations ended with a divergence (0.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 66.98 seconds\n",
      "Dumped pickle to bayes_results\\obj_Gerischer_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Macdonald_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 125.42 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Macdonald_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations saturated the maximum tree depth of 10 (0.25 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 85.57 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Macdonald_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 69.17 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_noiseless.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 125.47 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_noiseless.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Orazem_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 130.76 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Orazem_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:123 of 400 iterations saturated the maximum tree depth of 10 (30.8 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 110.41 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_Orazem_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations ended with a divergence (0.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 77.72 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_uniform_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 133.29 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_uniform_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:368 of 400 iterations saturated the maximum tree depth of 10 (92 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 129.10 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_RC_uniform_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 82.65 seconds\n",
      "Dumped pickle to bayes_results\\obj_RC_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Macdonald_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 67.29 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Macdonald_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 63.84 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Macdonald_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:2 of 400 iterations ended with a divergence (0.5 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 64.19 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_noiseless.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 92.96 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_noiseless.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Orazem_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 92.39 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Orazem_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 66.29 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_Orazem_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:2 of 400 iterations ended with a divergence (0.5 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 72.69 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_uniform_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations saturated the maximum tree depth of 10 (0.25 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 87.72 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_uniform_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 61.68 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC-RL_uniform_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:2 of 400 iterations ended with a divergence (0.5 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 71.48 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC-RL_uniform_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Macdonald_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 67.68 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Macdonald_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations ended with a divergence (0.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 68.63 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Macdonald_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations ended with a divergence (0.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 61.94 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_Macdonald_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_noiseless.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 92.20 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_noiseless.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Orazem_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 89.37 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_Orazem_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Orazem_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 62.58 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_Orazem_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_Orazem_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:2 of 400 iterations ended with a divergence (0.5 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 64.77 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_Orazem_2.5.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_uniform_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations saturated the maximum tree depth of 10 (0.25 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 87.35 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_uniform_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_uniform_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 62.89 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_uniform_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_ZARC_uniform_2.5.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 65.77 seconds\n",
      "Dumped pickle to bayes_results\\obj_ZARC_uniform_2.5.pkl\n",
      "Total fit time: 82.97 minutes\n"
     ]
    }
   ],
   "source": [
    "\"MCMC sampling\"\n",
    "# tau for plotting\n",
    "tau_plot = np.logspace(-7,2,200)\n",
    "start = time.time()\n",
    "\n",
    "for file in files:\n",
    "    print('-------------------------------')\n",
    "    print(file)\n",
    "    print('-------------------------------')\n",
    "    suffix = file[file.find('_'):]\n",
    "    Zoutfile = os.path.join('bayes_results',f'Zout{suffix}')\n",
    "    Goutfile = os.path.join('bayes_results',f'Gout{suffix}')\n",
    "    pkl = os.path.join('bayes_results','obj{}.pkl'.format(suffix[:-4]))\n",
    "    if file.split('_')[2]=='noiseless.csv':\n",
    "        sigma_min=0.005\n",
    "    else:\n",
    "        sigma_min=0.002\n",
    "        \n",
    "    if os.path.exists(Zoutfile) and os.path.exists(Goutfile):\n",
    "        print('Already ran')\n",
    "    else:\n",
    "        df = pd.read_csv(file)\n",
    "        Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "        \n",
    "        # fit\n",
    "        file_start = time.time()\n",
    "        dr.bayes_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=True,sigma_min=sigma_min)\n",
    "        print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "        \n",
    "        Z_pred = dr.predict(df['Freq'].values)\n",
    "        # Z credibility interval\n",
    "        Z_lo = dr.predict(df['Freq'].values,percentile=2.5)\n",
    "        Z_hi = dr.predict(df['Freq'].values,percentile=97.5)\n",
    "        Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag,Z_lo,Z_hi]).T,\n",
    "                             columns=['freq','Zreal','Zimag','Zlo','Zhi'])\n",
    "        Z_res['sigma_re'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[:len(df)]*dr._Z_scale\n",
    "        Z_res['sigma_im'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[len(df):]*dr._Z_scale\n",
    "        \n",
    "        g_pred = dr.drt(eval_tau=tau_plot)\n",
    "        # drt credibility interval\n",
    "        g_lo = dr.drt(eval_tau=tau_plot,percentile=2.5)\n",
    "        g_hi = dr.drt(eval_tau=tau_plot,percentile=97.5)\n",
    "        g_res = pd.DataFrame(np.array([tau_plot,g_pred,g_lo,g_hi]).T,\n",
    "                             columns=['tau','gamma','gamma_lo','gamma_hi'])\n",
    "        \n",
    "        Z_res.to_csv(Zoutfile,index=False)\n",
    "        g_res.to_csv(Goutfile,index=False)\n",
    "        \n",
    "        # pickle the drt object for access to all other attributes\n",
    "        save_pickle(dr,pkl)\n",
    "        \n",
    "print('Total fit time: {:.2f} minutes'.format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:2000 of 2000 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 509.13 seconds\n",
      "Dumped pickle to bayes_results\\obj_2RC_uniform_0.25_4x1000.pkl\n"
     ]
    }
   ],
   "source": [
    "\"Fit example file with 4 chains, 1000 iterations for comparison\"\n",
    "file = '../data/simulated/Z_2RC_uniform_0.25.csv'\n",
    "df = pd.read_csv(file)\n",
    "Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "suffix = file[file.find('_'):-4]\n",
    "Zoutfile = os.path.join('bayes_results',f'Zout{suffix}_4x1000.csv')\n",
    "Goutfile = os.path.join('bayes_results',f'Gout{suffix}_4x1000.csv')\n",
    "pkl = os.path.join('bayes_results',f'obj{suffix}_4x1000.pkl')\n",
    "tau_plot = np.logspace(-7,2,200)\n",
    "\n",
    "file_start = time.time()\n",
    "dr.bayes_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=True,warmup=500,sample=500,chains=4)\n",
    "print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "        \n",
    "Z_pred = dr.predict(df['Freq'].values)\n",
    "# Z credibility interval\n",
    "Z_lo = dr.predict(df['Freq'].values,percentile=2.5)\n",
    "Z_hi = dr.predict(df['Freq'].values,percentile=97.5)\n",
    "Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag,Z_lo,Z_hi]).T,\n",
    "                     columns=['freq','Zreal','Zimag','Zlo','Zhi'])\n",
    "Z_res['sigma_re'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[:len(df)]*dr._Z_scale\n",
    "Z_res['sigma_im'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[len(df):]*dr._Z_scale\n",
    "\n",
    "g_pred = dr.drt(eval_tau=tau_plot)\n",
    "# drt credibility interval\n",
    "g_lo = dr.drt(eval_tau=tau_plot,percentile=2.5)\n",
    "g_hi = dr.drt(eval_tau=tau_plot,percentile=97.5)\n",
    "g_res = pd.DataFrame(np.array([tau_plot,g_pred,g_lo,g_hi]).T,\n",
    "                     columns=['tau','gamma','gamma_lo','gamma_hi'])\n",
    "\n",
    "Z_res.to_csv(Zoutfile,index=False)\n",
    "g_res.to_csv(Goutfile,index=False)\n",
    "\n",
    "# pickle the drt object for access to all other attributes\n",
    "save_pickle(dr,pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated RL-ZARC-ZARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dr_trunc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-01843d3276ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrunc_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Zreal'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1j\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Zimag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdr_trunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mridge_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Freq'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dr_trunc' is not defined"
     ]
    }
   ],
   "source": [
    "dr_trunc = drt.DRT(basis_freq=np.logspace(6,-2,81))\n",
    "trunc_files = glob.glob('../data/simulated/Z_trunc*.csv')\n",
    "\n",
    "# fit one file to generate A matrices\n",
    "df = pd.read_csv(trunc_files[0])\n",
    "Z = df['Zreal'] + 1j*df['Zimag']\n",
    "dr_trunc.ridge_fit(df['Freq'].values,Z.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "../data/simulated\\Z_trunc_Macdonald_0.25.csv\n",
      "-------------------------------\n",
      "File fit time: 8.98 seconds\n",
      "Dumped pickle to map_results\\obj_trunc_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_trunc_Macdonald_1.0.csv\n",
      "-------------------------------\n",
      "File fit time: 2.17 seconds\n",
      "Dumped pickle to map_results\\obj_trunc_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_trunc_noiseless.csv\n",
      "-------------------------------\n",
      "File fit time: 10.80 seconds\n",
      "Dumped pickle to map_results\\obj_trunc_noiseless.pkl\n",
      "================================\n",
      "Total fit time: 0.40 minutes\n"
     ]
    }
   ],
   "source": [
    "\"MAP fits\"\n",
    "# tau for plotting\n",
    "tau_plot = np.logspace(-7,2,200)\n",
    "start = time.time()\n",
    "\n",
    "for file in trunc_files:\n",
    "    print('-------------------------------')\n",
    "    print(file)\n",
    "    print('-------------------------------')\n",
    "    suffix = file[file.find('_'):]\n",
    "    Zoutfile = os.path.join('map_results',f'Zout{suffix}')\n",
    "    Goutfile = os.path.join('map_results',f'Gout{suffix}')\n",
    "    pkl = os.path.join('map_results','obj{}.pkl'.format(suffix[:-4]))\n",
    "    if file.split('_')[2]=='noiseless.csv':\n",
    "        sigma_min=0.005\n",
    "    else:\n",
    "        sigma_min=0.002\n",
    "    if os.path.exists(Zoutfile) and os.path.exists(Goutfile):\n",
    "        print('Already ran')\n",
    "    else:\n",
    "        df = pd.read_csv(file)\n",
    "        Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "        # fit\n",
    "        file_start = time.time()\n",
    "        dr_trunc.map_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=False,sigma_min=sigma_min)\n",
    "        print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "        \n",
    "        # save results\n",
    "        Z_pred = dr_trunc.predict(df['Freq'].values)\n",
    "        Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag]).T,columns=['freq','Zreal','Zimag'])\n",
    "        Z_res['sigma_re'] = dr_trunc._opt_result['sigma_tot'][:len(df)]*dr_trunc._Z_scale\n",
    "        Z_res['sigma_im'] = dr_trunc._opt_result['sigma_tot'][len(df):]*dr_trunc._Z_scale\n",
    "        \n",
    "        g_pred = dr_trunc.drt(eval_tau=tau_plot)\n",
    "        g_res = pd.DataFrame(np.array([tau_plot,g_pred]).T,\n",
    "                             columns=['tau','gamma'])\n",
    "        Z_res.to_csv(Zoutfile,index=False)\n",
    "        g_res.to_csv(Goutfile,index=False)\n",
    "        \n",
    "        # pickle the drt object for access to all other attributes\n",
    "        save_pickle(dr_trunc,pkl)\n",
    "        \n",
    "print('================================')        \n",
    "print('Total fit time: {:.2f} minutes'.format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "../data/simulated\\Z_trunc_Macdonald_0.25.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\drt.py:311: UserWarning: Hyperparametric solution did not converge within 20 iterations\n",
      "  warnings.warn(f'Hyperparametric solution did not converge within {max_iter} iterations')\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 114.40 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\stan_models.py:7: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped pickle to bayes_results\\obj_trunc_Macdonald_0.25.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_trunc_Macdonald_1.0.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:1 of 400 iterations ended with a divergence (0.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 61.44 seconds\n",
      "Dumped pickle to bayes_results\\obj_trunc_Macdonald_1.0.pkl\n",
      "-------------------------------\n",
      "../data/simulated\\Z_trunc_noiseless.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:400 of 400 iterations saturated the maximum tree depth of 10 (100 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 115.07 seconds\n",
      "Dumped pickle to bayes_results\\obj_trunc_noiseless.pkl\n",
      "Total fit time: 4.88 minutes\n"
     ]
    }
   ],
   "source": [
    "\"MCMC sampling\"\n",
    "# tau for plotting\n",
    "tau_plot = np.logspace(-7,2,200)\n",
    "start = time.time()\n",
    "\n",
    "for file in trunc_files:\n",
    "    print('-------------------------------')\n",
    "    print(file)\n",
    "    print('-------------------------------')\n",
    "    suffix = file[file.find('_'):]\n",
    "    Zoutfile = os.path.join('bayes_results',f'Zout{suffix}')\n",
    "    Goutfile = os.path.join('bayes_results',f'Gout{suffix}')\n",
    "    pkl = os.path.join('bayes_results','obj{}.pkl'.format(suffix[:-4]))\n",
    "    if file.split('_')[2]=='noiseless.csv':\n",
    "        sigma_min=0.005\n",
    "    else:\n",
    "        sigma_min=0.002\n",
    "        \n",
    "    if os.path.exists(Zoutfile) and os.path.exists(Goutfile):\n",
    "        print('Already ran')\n",
    "    else:\n",
    "        df = pd.read_csv(file)\n",
    "        Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "        \n",
    "        # fit\n",
    "        file_start = time.time()\n",
    "        dr_trunc.bayes_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=True,sigma_min=sigma_min)\n",
    "        print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "        \n",
    "        Z_pred = dr_trunc.predict(df['Freq'].values)\n",
    "        # Z credibility interval\n",
    "        Z_lo = dr_trunc.predict(df['Freq'].values,percentile=2.5)\n",
    "        Z_hi = dr_trunc.predict(df['Freq'].values,percentile=97.5)\n",
    "        Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag,Z_lo,Z_hi]).T,\n",
    "                             columns=['freq','Zreal','Zimag','Zlo','Zhi'])\n",
    "        Z_res['sigma_re'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[:len(df)]*dr._Z_scale\n",
    "        Z_res['sigma_im'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[len(df):]*dr._Z_scale\n",
    "        \n",
    "        g_pred = dr_trunc.drt(eval_tau=tau_plot)\n",
    "        # drt credibility interval\n",
    "        g_lo = dr_trunc.drt(eval_tau=tau_plot,percentile=2.5)\n",
    "        g_hi = dr_trunc.drt(eval_tau=tau_plot,percentile=97.5)\n",
    "        g_res = pd.DataFrame(np.array([tau_plot,g_pred,g_lo,g_hi]).T,\n",
    "                             columns=['tau','gamma','gamma_lo','gamma_hi'])\n",
    "        \n",
    "        Z_res.to_csv(Zoutfile,index=False)\n",
    "        g_res.to_csv(Goutfile,index=False)\n",
    "        \n",
    "        # pickle the drt object for access to all other attributes\n",
    "        save_pickle(dr_trunc,pkl)\n",
    "        \n",
    "print('Total fit time: {:.2f} minutes'.format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental data\n",
    "## LIB data from DRTtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\drt.py:1035: RuntimeWarning: overflow encountered in exp\n",
      "  return phi(y,epsilon)/(1+np.exp(2*(y+np.log(w_n*t_m))))\n",
      "../bayes-drt\\drt.py:1117: IntegrationWarning: The integral is probably divergent, or slowly convergent.\n",
      "  A_main[n,:] = [quad(func,limits[0],limits[1],args=(w_n,t_m,epsilon),epsabs=1e-4)[0] for t_m in tau]\n",
      "../bayes-drt\\drt.py:311: UserWarning: Hyperparametric solution did not converge within 20 iterations\n",
      "  warnings.warn(f'Hyperparametric solution did not converge within {max_iter} iterations')\n"
     ]
    }
   ],
   "source": [
    "lib_files = ['../data/experimental/DRTtools_LIB_data.txt',\n",
    "             '../data/experimental/DRTtools_LIB_data_qtr.csv'\n",
    "            ]\n",
    "\n",
    "dr_lib = drt.DRT(basis_freq=np.logspace(4,-5,101))\n",
    "\n",
    "# run ridge_fit to generate A matrices\n",
    "lib_df = pd.read_csv(lib_files[0],sep='\\t',header=None)\n",
    "lib_df = pd.DataFrame(lib_df.values,columns=['Freq','Zreal','Zimag'])\n",
    "Z_lib = lib_df['Zreal'] + 1j*lib_df['Zimag']\n",
    "f = lib_df['Freq'].values\n",
    "Z_lib = Z_lib\n",
    "dr_lib.ridge_fit(f,Z_lib.values)\n",
    "\n",
    "# finer tau for plotting\n",
    "tau_plot = np.logspace(np.log10(np.min(dr_lib.tau)),np.log10(np.max(dr_lib.tau)),200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "../data/experimental/DRTtools_LIB_data.txt\n",
      "-------------------------------\n",
      "File fit time: 23.43 seconds\n",
      "Dumped pickle to map_results\\obj_LIB_data.pkl\n",
      "-------------------------------\n",
      "../data/experimental/DRTtools_LIB_data_qtr.csv\n",
      "-------------------------------\n",
      "File fit time: 11.20 seconds\n",
      "Dumped pickle to map_results\\obj_LIB_data_qtr.pkl\n",
      "Total fit time: 0.58 minutes\n"
     ]
    }
   ],
   "source": [
    "\"MAP fits\"\n",
    "start = time.time()\n",
    "\n",
    "for file in lib_files:\n",
    "    print('-------------------------------')\n",
    "    print(file)\n",
    "    print('-------------------------------')\n",
    "    suffix = file[file.find('_'):]\n",
    "    # strip file extension\n",
    "    suffix = suffix[:suffix.find('.')]\n",
    "    Zoutfile = os.path.join('map_results',f'Zout{suffix}.csv')\n",
    "    Goutfile = os.path.join('map_results',f'Gout{suffix}.csv')\n",
    "    pkl = os.path.join('map_results','obj{}.pkl'.format(suffix))\n",
    "    if os.path.exists(Zoutfile) and os.path.exists(Goutfile):\n",
    "        print('Already ran')\n",
    "    else:\n",
    "        if file[-3:]=='txt':\n",
    "            df = pd.read_csv(file,sep='\\t',header=None)\n",
    "            df = pd.DataFrame(df.values,columns=['Freq','Zreal','Zimag'])\n",
    "        else:\n",
    "            df = pd.read_csv(file)\n",
    "        Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "        # fit\n",
    "        file_start = time.time()\n",
    "        # initializing from the ridge solution may be helpful for faster convergence for more complex spectra\n",
    "        dr_lib.map_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=True,max_iter=30e3)\n",
    "        print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "        # save results\n",
    "        Z_pred = dr_lib.predict(df['Freq'].values)\n",
    "        Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag]).T,columns=['freq','Zreal','Zimag'])\n",
    "        g_pred = dr_lib.drt(eval_tau=tau_plot)\n",
    "        g_res = pd.DataFrame(np.array([tau_plot,g_pred]).T,\n",
    "                             columns=['tau','gamma'])\n",
    "        Z_res.to_csv(Zoutfile,index=False)\n",
    "        g_res.to_csv(Goutfile,index=False)\n",
    "        \n",
    "        # pickle the drt object for access to all other attributes\n",
    "        save_pickle(dr_lib,pkl)\n",
    "        \n",
    "print('Total fit time: {:.2f} minutes'.format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "../data/experimental/DRTtools_LIB_data.txt\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:1 of 400 iterations ended with a divergence (0.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:399 of 400 iterations saturated the maximum tree depth of 10 (99.8 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 195.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\stan_models.py:7: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped pickle to bayes_results\\obj_LIB_data.pkl\n",
      "-------------------------------\n",
      "../data/experimental/DRTtools_LIB_data_qtr.csv\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n",
      "WARNING:pystan:44 of 400 iterations saturated the maximum tree depth of 10 (11 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 120.17 seconds\n",
      "Dumped pickle to bayes_results\\obj_LIB_data_qtr.pkl\n",
      "Total fit time: 5.26 minutes\n"
     ]
    }
   ],
   "source": [
    "\"MCMC sampling\"\n",
    "# tau for plotting\n",
    "tau_plot = np.logspace(np.log10(np.min(dr_lib.tau)),np.log10(np.max(dr_lib.tau)),200)\n",
    "start = time.time()\n",
    "\n",
    "for file in lib_files:\n",
    "    print('-------------------------------')\n",
    "    print(file)\n",
    "    print('-------------------------------')\n",
    "    suffix = file[file.find('_'):]\n",
    "    # strip file extension\n",
    "    suffix = suffix[:suffix.find('.')]\n",
    "    Zoutfile = os.path.join('bayes_results',f'Zout{suffix}.csv')\n",
    "    Goutfile = os.path.join('bayes_results',f'Gout{suffix}.csv')\n",
    "    pkl = os.path.join('bayes_results','obj{}.pkl'.format(suffix))\n",
    "    if os.path.exists(Zoutfile) and os.path.exists(Goutfile):\n",
    "        print('Already ran')\n",
    "    else:\n",
    "        if file[-3:]=='txt':\n",
    "            df = pd.read_csv(file,sep='\\t',header=None)\n",
    "            df = pd.DataFrame(df.values,columns=['Freq','Zreal','Zimag'])\n",
    "        else:\n",
    "            df = pd.read_csv(file)\n",
    "        Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "        \n",
    "        # fit\n",
    "        file_start = time.time()\n",
    "        # initializing from the ridge solution may be helpful for sampling for more complex spectra\n",
    "        dr_lib.bayes_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=True)\n",
    "        print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "        \n",
    "        Z_pred = dr_lib.predict(df['Freq'].values)\n",
    "        # Z credibility interval\n",
    "        Z_lo = dr_lib.predict(df['Freq'].values,percentile=2.5)\n",
    "        Z_hi = dr_lib.predict(df['Freq'].values,percentile=97.5)\n",
    "        Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag,Z_lo,Z_hi]).T,\n",
    "                             columns=['freq','Zreal','Zimag','Zlo','Zhi'])\n",
    "        Z_res['sigma_re'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[:len(df)]*dr._Z_scale\n",
    "        Z_res['sigma_im'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[len(df):]*dr._Z_scale\n",
    "        \n",
    "        g_pred = dr_lib.drt(eval_tau=tau_plot)\n",
    "        # drt crediibility interval\n",
    "        g_lo = dr_lib.drt(eval_tau=tau_plot,percentile=2.5)\n",
    "        g_hi = dr_lib.drt(eval_tau=tau_plot,percentile=97.5)\n",
    "        g_res = pd.DataFrame(np.array([tau_plot,g_pred,g_lo,g_hi]).T,\n",
    "                             columns=['tau','gamma','gamma_lo','gamma_hi'])\n",
    "        \n",
    "        Z_res.to_csv(Zoutfile,index=False)\n",
    "        g_res.to_csv(Goutfile,index=False)\n",
    "        \n",
    "        # pickle the drt object for access to all other attributes\n",
    "        save_pickle(dr_lib,pkl)\n",
    "        \n",
    "print('Total fit time: {:.2f} minutes'.format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protonic ceramic microelectrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tco_file = '../data/experimental/PDAC_COM3_02109_Contact10_2065C_500C.txt'\n",
    "tco_df = gt.read_eis_zdata(tco_file)\n",
    "\n",
    "dr_tco = drt.DRT(basis_freq=np.logspace(7,-3,101))\n",
    "\n",
    "# run ridge_fit to generate A matrices\n",
    "Z_tco = tco_df['Zreal'] + 1j*tco_df['Zimag']\n",
    "f = tco_df['Freq'].values\n",
    "dr_tco.ridge_fit(f,Z_tco.values)\n",
    "\n",
    "# finer tau for plotting\n",
    "tau_plot_tco = np.logspace(np.log10(np.min(dr_tco.tau)),np.log10(np.max(dr_tco.tau)),200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Outliers=True\n",
      "-------------------------------\n",
      "File fit time: 28.22 seconds\n",
      "Dumped pickle to map_results\\obj_PDAC_outliers.pkl\n",
      "-------------------------------\n",
      "Outliers=False\n",
      "-------------------------------\n",
      "File fit time: 13.70 seconds\n",
      "Dumped pickle to map_results\\obj_PDAC.pkl\n",
      "Total fit time: 0.70 minutes\n"
     ]
    }
   ],
   "source": [
    "\"MAP fits\"\n",
    "start = time.time()\n",
    "file = tco_file\n",
    "\n",
    "for outliers in [True,False]:\n",
    "    print('-------------------------------')\n",
    "    print(f'Outliers={outliers}')\n",
    "    print('-------------------------------')\n",
    "    suffix = '_PDAC'\n",
    "    if outliers:\n",
    "        suffix += '_outliers'\n",
    "    Zoutfile = os.path.join('map_results',f'Zout{suffix}.csv')\n",
    "    Goutfile = os.path.join('map_results',f'Gout{suffix}.csv')\n",
    "    pkl = os.path.join('map_results','obj{}.pkl'.format(suffix))\n",
    "    if os.path.exists(Zoutfile) and os.path.exists(Goutfile):\n",
    "        print('Already ran')\n",
    "    else:\n",
    "        df = gt.read_eis_zdata(file)\n",
    "        Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "        # fit\n",
    "        file_start = time.time()\n",
    "        # initializing from the ridge solution may be helpful for faster convergence for more complex spectra\n",
    "        dr_tco.map_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=True,max_iter=30e3,outliers=outliers)\n",
    "        print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "        # save results\n",
    "        Z_pred = dr_tco.predict(df['Freq'].values)\n",
    "        Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag]).T,columns=['freq','Zreal','Zimag'])\n",
    "        g_pred = dr_tco.drt(eval_tau=tau_plot_tco)\n",
    "        g_res = pd.DataFrame(np.array([tau_plot_tco,g_pred]).T,\n",
    "                             columns=['tau','gamma'])\n",
    "        Z_res.to_csv(Zoutfile,index=False)\n",
    "        g_res.to_csv(Goutfile,index=False)\n",
    "        \n",
    "        # pickle the drt object for access to all other attributes\n",
    "        save_pickle(dr_tco,pkl)\n",
    "        \n",
    "print('Total fit time: {:.2f} minutes'.format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Outliers=True\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\drt.py:311: UserWarning: Hyperparametric solution did not converge within 20 iterations\n",
      "  warnings.warn(f'Hyperparametric solution did not converge within {max_iter} iterations')\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:17 of 400 iterations ended with a divergence (4.25 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.9 to remove the divergences.\n",
      "WARNING:pystan:191 of 400 iterations saturated the maximum tree depth of 10 (47.8 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fit time: 222.17 seconds\n",
      "Dumped pickle to bayes_results\\obj_PDAC_outliers.pkl\n",
      "-------------------------------\n",
      "Outliers=False\n",
      "-------------------------------\n",
      "Already ran\n",
      "Total fit time: 3.71 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../bayes-drt\\stan_models.py:7: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n"
     ]
    }
   ],
   "source": [
    "\"MCMC sampling\"\n",
    "# tau for plotting\n",
    "start = time.time()\n",
    "\n",
    "file = tco_file\n",
    "for outliers in [True,False]:\n",
    "    print('-------------------------------')\n",
    "    print(f'Outliers={outliers}')\n",
    "    print('-------------------------------')\n",
    "    suffix = '_PDAC'\n",
    "    if outliers:\n",
    "        suffix += '_outliers'\n",
    "        \n",
    "    Zoutfile = os.path.join('bayes_results',f'Zout{suffix}.csv')\n",
    "    Goutfile = os.path.join('bayes_results',f'Gout{suffix}.csv')\n",
    "    pkl = os.path.join('bayes_results','obj{}.pkl'.format(suffix))\n",
    "    \n",
    "    if os.path.exists(Zoutfile) and os.path.exists(Goutfile):\n",
    "        print('Already ran')\n",
    "    else:\n",
    "        df = gt.read_eis_zdata(file)\n",
    "        Z = df['Zreal'].values + 1j*df['Zimag'].values\n",
    "\n",
    "        # fit\n",
    "        file_start = time.time()\n",
    "        # initializing from the ridge solution may be helpful for sampling for more complex spectra\n",
    "        dr_tco.bayes_fit(df['Freq'].values,Z,dZ=False,init_from_ridge=True,outliers=outliers)\n",
    "        print('File fit time: {:.2f} seconds'.format(time.time()-file_start))\n",
    "\n",
    "        Z_pred = dr_tco.predict(df['Freq'].values)\n",
    "        # Z credibility interval\n",
    "        Z_lo = dr_tco.predict(df['Freq'].values,percentile=2.5)\n",
    "        Z_hi = dr_tco.predict(df['Freq'].values,percentile=97.5)\n",
    "        Z_res = pd.DataFrame(np.array([df['Freq'],Z_pred.real,Z_pred.imag,Z_lo,Z_hi]).T,\n",
    "                             columns=['freq','Zreal','Zimag','Zlo','Zhi'])\n",
    "        Z_res['sigma_re'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[:len(df)]*dr._Z_scale\n",
    "        Z_res['sigma_im'] = np.mean(dr._sample_result['sigma_tot'],axis=0)[len(df):]*dr._Z_scale\n",
    "\n",
    "        g_pred = dr_tco.drt(eval_tau=tau_plot_tco)\n",
    "        # drt crediibility interval\n",
    "        g_lo = dr_tco.drt(eval_tau=tau_plot_tco,percentile=2.5)\n",
    "        g_hi = dr_tco.drt(eval_tau=tau_plot_tco,percentile=97.5)\n",
    "        g_res = pd.DataFrame(np.array([tau_plot_tco,g_pred,g_lo,g_hi]).T,\n",
    "                             columns=['tau','gamma','gamma_lo','gamma_hi'])\n",
    "\n",
    "        Z_res.to_csv(Zoutfile,index=False)\n",
    "        g_res.to_csv(Goutfile,index=False)\n",
    "\n",
    "        # pickle the drt object for access to all other attributes\n",
    "        save_pickle(dr_tco,pkl)\n",
    "        \n",
    "print('Total fit time: {:.2f} minutes'.format((time.time()-start)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
